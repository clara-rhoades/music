{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7704c3ea",
   "metadata": {},
   "source": [
    "## Project 3 - Neo4j Graph Prep\n",
    "Semester: Spring 2025 - Section 9\n",
    "\n",
    "Course: w205 â€“ Fundamentals of Data Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f97cbf",
   "metadata": {},
   "source": [
    "### Importing Libraries & Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ecc22cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from psycopg2.extras import execute_values\n",
    "from neo4j import GraphDatabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8beefd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install kaggle\n",
    "# !apt-get update && apt-get install -y unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d863a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir -p ~/.kaggle\n",
    "# !cp /user/projects/project-3-kalafosaurus/code/kaggle.json ~/.kaggle/\n",
    "# !chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67a3e11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !kaggle datasets download -d andrewmvd/spotify-playlists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a703b5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip spotify-playlists.zip -d spotify_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d440b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['user_id', ' \"artistname\"', ' \"trackname\"', ' \"playlistname\"']\n"
     ]
    }
   ],
   "source": [
    "cols = pd.read_csv('/user/projects/project-3-kalafosaurus/code/spotify_data/spotify_dataset.csv', nrows=0)\n",
    "print(cols.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1152f71a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>artistname</th>\n",
       "      <th>trackname</th>\n",
       "      <th>playlistname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9cc0cfd4d7d7885102480dd99e7a90d6</td>\n",
       "      <td>Elvis Costello</td>\n",
       "      <td>(The Angels Wanna Wear My) Red Shoes</td>\n",
       "      <td>HARD ROCK 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9cc0cfd4d7d7885102480dd99e7a90d6</td>\n",
       "      <td>Elvis Costello &amp; The Attractions</td>\n",
       "      <td>(What's So Funny 'Bout) Peace, Love And Unders...</td>\n",
       "      <td>HARD ROCK 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9cc0cfd4d7d7885102480dd99e7a90d6</td>\n",
       "      <td>Tiffany Page</td>\n",
       "      <td>7 Years Too Late</td>\n",
       "      <td>HARD ROCK 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9cc0cfd4d7d7885102480dd99e7a90d6</td>\n",
       "      <td>Elvis Costello &amp; The Attractions</td>\n",
       "      <td>Accidents Will Happen</td>\n",
       "      <td>HARD ROCK 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9cc0cfd4d7d7885102480dd99e7a90d6</td>\n",
       "      <td>Elvis Costello</td>\n",
       "      <td>Alison</td>\n",
       "      <td>HARD ROCK 2010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            user_id                        artistname  \\\n",
       "0  9cc0cfd4d7d7885102480dd99e7a90d6                    Elvis Costello   \n",
       "1  9cc0cfd4d7d7885102480dd99e7a90d6  Elvis Costello & The Attractions   \n",
       "2  9cc0cfd4d7d7885102480dd99e7a90d6                      Tiffany Page   \n",
       "3  9cc0cfd4d7d7885102480dd99e7a90d6  Elvis Costello & The Attractions   \n",
       "4  9cc0cfd4d7d7885102480dd99e7a90d6                    Elvis Costello   \n",
       "\n",
       "                                           trackname    playlistname  \n",
       "0               (The Angels Wanna Wear My) Red Shoes  HARD ROCK 2010  \n",
       "1  (What's So Funny 'Bout) Peace, Love And Unders...  HARD ROCK 2010  \n",
       "2                                   7 Years Too Late  HARD ROCK 2010  \n",
       "3                              Accidents Will Happen  HARD ROCK 2010  \n",
       "4                                             Alison  HARD ROCK 2010  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\n",
    "    '/user/projects/project-3-kalafosaurus/code/spotify_data/spotify_dataset.csv',\n",
    "    names=['user_id', 'artistname', 'trackname', 'playlistname'],\n",
    "    header=0,\n",
    "    on_bad_lines='skip'\n",
    ")\n",
    "df.dropna(inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4668bdbf",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e50484d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape:\n",
      "(12856838, 4)\n",
      "\n",
      "Missing values:\n",
      "user_id         0\n",
      "artistname      0\n",
      "trackname       0\n",
      "playlistname    0\n",
      "dtype: int64\n",
      "\n",
      "Unique counts:\n",
      "user_id           15914\n",
      "artistname       289603\n",
      "trackname       2004523\n",
      "playlistname     157320\n",
      "dtype: int64\n",
      "\n",
      "Top 10 artists:\n",
      "Daft Punk             36086\n",
      "Coldplay              35485\n",
      "Radiohead             31429\n",
      "The Rolling Stones    30814\n",
      "Kanye West            29111\n",
      "JAY Z                 28928\n",
      "Eminem                28894\n",
      "Queen                 28079\n",
      "David Bowie           27791\n",
      "Michael Jackson       26335\n",
      "Name: artistname, dtype: int64\n",
      "\n",
      "Top 10 tracks:\n",
      "Intro          6675\n",
      "Home           5600\n",
      "Closer         3548\n",
      "Runaway        3349\n",
      "Hold On        3224\n",
      "Radioactive    3188\n",
      "Forever        3055\n",
      "Stay           2992\n",
      "Alive          2936\n",
      "Wake Me Up     2793\n",
      "Name: trackname, dtype: int64\n",
      "\n",
      "Top 10 playlist names:\n",
      "Starred                  1334319\n",
      "Liked from Radio          180079\n",
      "Favoritas de la radio      30425\n",
      "Rock                       30107\n",
      "2014                       22674\n",
      "Christmas                  22236\n",
      "2013                       20870\n",
      "Work                       18408\n",
      "Jazz                       18266\n",
      "Indie                      17858\n",
      "Name: playlistname, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset shape:\")\n",
    "print(df.shape)\n",
    "print()\n",
    "\n",
    "print(\"Missing values:\")\n",
    "print(df.isna().sum())\n",
    "print()\n",
    "\n",
    "print(\"Unique counts:\")\n",
    "print(df.nunique())\n",
    "print()\n",
    "\n",
    "print(\"Top 10 artists:\")\n",
    "print(df['artistname'].value_counts().head(10))\n",
    "print()\n",
    "\n",
    "print(\"Top 10 tracks:\")\n",
    "print(df['trackname'].value_counts().head(10))\n",
    "print()\n",
    "\n",
    "print(\"Top 10 playlist names:\")\n",
    "print(df['playlistname'].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9976144a",
   "metadata": {},
   "source": [
    "### Postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd31afd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_select_query_pandas(query, rollback_before_flag, rollback_after_flag):\n",
    "    if rollback_before_flag:\n",
    "        connection.rollback()\n",
    "    \n",
    "    df = pd.read_sql_query(query, connection)\n",
    "    \n",
    "    if rollback_after_flag:\n",
    "        connection.rollback()\n",
    "\n",
    "    for column in df:\n",
    "        if df[column].dtype == \"float64\":\n",
    "            if all((np.isnan(x) or x == int(x)) for x in df[column]):\n",
    "                df[column] = df[column].astype('Int64')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a027d732",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = psycopg2.connect(\n",
    "    user=\"postgres\",\n",
    "    password=\"ucb\",\n",
    "    host=\"postgres\",\n",
    "    port=\"5432\",\n",
    "    database=\"postgres\"\n",
    ")\n",
    "\n",
    "cur = connection.cursor()\n",
    "\n",
    "cur.execute('DROP TABLE IF EXISTS spotify_data;')\n",
    "cur.execute('''\n",
    "    CREATE TABLE spotify_data (\n",
    "        user_id VARCHAR(100),\n",
    "        artistname VARCHAR(500),\n",
    "        trackname VARCHAR(500),\n",
    "        playlistname VARCHAR(500)\n",
    "    );\n",
    "''')\n",
    "connection.commit()\n",
    "\n",
    "# Prepare bulk data\n",
    "data_tuples = list(df.itertuples(index=False, name=None))\n",
    "\n",
    "# Fast bulk insert\n",
    "insert_query = '''\n",
    "    INSERT INTO spotify_data (user_id, artistname, trackname, playlistname)\n",
    "    VALUES %s;\n",
    "'''\n",
    "execute_values(cur, insert_query, data_tuples)\n",
    "connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e64e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "rollback_before_flag = True\n",
    "rollback_after_flag = True\n",
    "\n",
    "query = '''\n",
    "WITH artist_pairs AS (\n",
    "  SELECT a1.artistname as artist1, a2.artistname as artist2, \n",
    "         COUNT(DISTINCT a1.playlistname) as shared_playlists\n",
    "  FROM spotify_data a1\n",
    "  JOIN spotify_data a2 ON a1.playlistname = a2.playlistname \n",
    "                      AND a1.artistname < a2.artistname\n",
    "  GROUP BY a1.artistname, a2.artistname\n",
    "  HAVING COUNT(DISTINCT a1.playlistname) > 1\n",
    "  ORDER BY shared_playlists DESC\n",
    "  LIMIT 2000\n",
    ")\n",
    "SELECT artistname, trackname, COUNT(*) AS play_count\n",
    "FROM spotify_data\n",
    "WHERE artistname IN (SELECT artist1 FROM artist_pairs UNION SELECT artist2 FROM artist_pairs)\n",
    "GROUP BY artistname, trackname\n",
    "ORDER BY play_count DESC\n",
    "LIMIT 10000;\n",
    "'''\n",
    "\n",
    "df_pairs = my_select_query_pandas(query, rollback_before_flag, rollback_after_flag)\n",
    "df_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae58ae97",
   "metadata": {},
   "source": [
    "### Neo4j Nodes and Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b8ed34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Artist nodes\n",
    "df_artists = df_pairs[['artistname']].drop_duplicates().rename(columns={'artistname': 'name'})\n",
    "df_artists['label'] = 'Artist'\n",
    "\n",
    "# Track nodes\n",
    "df_tracks = df_pairs[['trackname']].drop_duplicates().rename(columns={'trackname': 'name'})\n",
    "df_tracks['label'] = 'Track'\n",
    "\n",
    "# Relationships: Artist -[:PERFORMED]-> Track\n",
    "df_edges = df_pairs.rename(columns={\n",
    "    'artistname': 'source',\n",
    "    'trackname': 'target',\n",
    "    'play_count': 'weight'\n",
    "})\n",
    "df_edges['type'] = 'PERFORMED'\n",
    "\n",
    "df_artists.head(), df_tracks.head(), df_edges.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f8d7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_artists.to_csv(\"/user/projects/project-3-kalafosaurus/code/artists.csv\", index=False)\n",
    "df_tracks.to_csv(\"/user/projects/project-3-kalafosaurus/code/tracks.csv\", index=False)\n",
    "df_edges.to_csv(\"/user/projects/project-3-kalafosaurus/code/edges.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da45abf4",
   "metadata": {},
   "source": [
    "### Neo4j Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea96a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "neo4j_uri = \"bolt://neo4j:7687\"\n",
    "neo4j_user = \"neo4j\"\n",
    "neo4j_pass = \"ucb_mids_w205\"\n",
    "\n",
    "driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_pass))\n",
    "session = driver.session(database=\"neo4j\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e74db45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test connection\n",
    "# session.run(\"MATCH (n) RETURN n LIMIT 5\").data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af36d7c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Clean everything\n",
    "session.run(\"MATCH (n) DETACH DELETE n\")\n",
    "try:\n",
    "    session.run(\"CALL gds.graph.drop('spotify_graph', false)\")\n",
    "    print(\"Dropped existing graph projection\")\n",
    "except Exception as e:\n",
    "    print(f\"No existing graph projection to drop or error: {e}\")\n",
    "\n",
    "# Create Artist nodes from dataframe\n",
    "artists = df_pairs['artistname'].unique()\n",
    "for artist in artists:\n",
    "    session.run(\n",
    "        \"CREATE (a:Artist {name: $name})\",\n",
    "        name=artist\n",
    "    )\n",
    "\n",
    "# Create Track nodes directly from dataframe\n",
    "tracks = df_pairs['trackname'].unique()\n",
    "for track in tracks:\n",
    "    session.run(\n",
    "        \"CREATE (t:Track {name: $name})\",\n",
    "        name=track\n",
    "    )\n",
    "\n",
    "# Create indexes\n",
    "session.run(\"CREATE INDEX artist_name IF NOT EXISTS FOR (a:Artist) ON (a.name)\")\n",
    "session.run(\"CREATE INDEX track_name IF NOT EXISTS FOR (t:Track) ON (t.name)\")\n",
    "\n",
    "# Create relationships in batches\n",
    "batch_size = 100\n",
    "for i in range(0, len(df_pairs), batch_size):\n",
    "    batch = df_pairs.iloc[i:i+batch_size]\n",
    "    for _, row in batch.iterrows():\n",
    "        session.run(\n",
    "            \"\"\"\n",
    "            MATCH (a:Artist {name: $artist}), (t:Track {name: $track})\n",
    "            CREATE (a)-[:PERFORMED {weight: $weight}]->(t)\n",
    "            \"\"\",\n",
    "            artist=row['artistname'],\n",
    "            track=row['trackname'],\n",
    "            weight=float(row['play_count'])\n",
    "        )\n",
    "    print(f\"Processed {min(i+batch_size, len(df_pairs))} of {len(df_pairs)} relationships\")\n",
    "\n",
    "# Add playlist data and co-occurrence relationships\n",
    "# a. Create playlist nodes\n",
    "playlist_names = df['playlistname'].unique()\n",
    "for playlist in playlist_names[:1000]:  # Limit to first 1000 playlists for performance\n",
    "    session.run(\n",
    "        \"CREATE (p:Playlist {name: $name})\",\n",
    "        name=playlist\n",
    "    )\n",
    "\n",
    "# b. Create INCLUDED_IN relationships (Track to Playlist)\n",
    "batch_size = 100\n",
    "playlist_data = df[['trackname', 'playlistname']].drop_duplicates()\n",
    "for i in range(0, len(playlist_data), batch_size):\n",
    "    batch = playlist_data.iloc[i:i+batch_size]\n",
    "    for _, row in batch.iterrows():\n",
    "        session.run(\n",
    "            \"\"\"\n",
    "            MATCH (t:Track {name: $track}), (p:Playlist {name: $playlist})\n",
    "            CREATE (t)-[:INCLUDED_IN]->(p)\n",
    "            \"\"\",\n",
    "            track=row['trackname'],\n",
    "            playlist=row['playlistname']\n",
    "        )\n",
    "    print(f\"Processed {min(i+batch_size, len(playlist_data))} of {len(playlist_data)} playlist relationships\")\n",
    "\n",
    "# c. Create graph projection for algorithms\n",
    "print(\"Creating graph projection...\")\n",
    "try:\n",
    "    session.run(\"\"\"\n",
    "    CALL gds.graph.project(\n",
    "        'spotify_graph',\n",
    "        ['Artist', 'Track', 'Playlist'],\n",
    "        {\n",
    "            PERFORMED: {\n",
    "                orientation: 'NATURAL',\n",
    "                properties: {\n",
    "                    weight: {\n",
    "                        property: 'weight',\n",
    "                        defaultValue: 1.0\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            INCLUDED_IN: {\n",
    "                orientation: 'NATURAL'\n",
    "            },\n",
    "            SIMILAR_TO: {\n",
    "                orientation: 'UNDIRECTED',\n",
    "                properties: {\n",
    "                    weight: {\n",
    "                        property: 'weight',\n",
    "                        defaultValue: 1.0\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    );\n",
    "    \"\"\")\n",
    "    print(\"Graph projection created successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating graph projection: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20465549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verifying loaded data\n",
    "result_artists = session.run(\"MATCH (a:Artist) RETURN a.name LIMIT 10\")\n",
    "result_tracks = session.run(\"MATCH (t:Track) RETURN t.name LIMIT 10\")\n",
    "result_relationships = session.run(\"MATCH (a:Artist)-[:PERFORMED]->(t:Track) RETURN a.name, t.name LIMIT 10\")\n",
    "\n",
    "print(\"Artists in Neo4j:\")\n",
    "for record in result_artists:\n",
    "    print(record[\"a.name\"])\n",
    "\n",
    "print(\"\\nTracks in Neo4j:\")\n",
    "for record in result_tracks:\n",
    "    print(record[\"t.name\"])\n",
    "\n",
    "print(\"\\nRelationships (Artist -[:PERFORMED]-> Track):\")\n",
    "for record in result_relationships:\n",
    "    print(f\"Artist: {record['a.name']} performed Track: {record['t.name']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce637d9",
   "metadata": {},
   "source": [
    "### Run Graph Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05a47a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. PageRank\n",
    "session.run(\"\"\"\n",
    "CALL gds.pageRank.write('spotify_graph', {\n",
    "    writeProperty: 'pagerank',\n",
    "    relationshipWeightProperty: 'weight',\n",
    "    maxIterations: 20,\n",
    "    dampingFactor: 0.85\n",
    "})\n",
    "\"\"\")\n",
    "\n",
    "# 2. Degree Centrality\n",
    "session.run(\"\"\"\n",
    "CALL gds.degree.write('spotify_graph', {\n",
    "    writeProperty: 'degree',\n",
    "    relationshipWeightProperty: 'weight'\n",
    "})\n",
    "\"\"\")\n",
    "\n",
    "# 3. Community Detection with Louvain\n",
    "session.run(\"\"\"\n",
    "CALL gds.louvain.write('spotify_graph', {\n",
    "    writeProperty: 'community',\n",
    "    relationshipWeightProperty: 'weight'\n",
    "})\n",
    "\"\"\")\n",
    "\n",
    "# 4. Create artist similarity network\n",
    "session.run(\"MATCH ()-[r:SIMILAR_TO]-() DELETE r\")  # Clear existing\n",
    "\n",
    "session.run(\"\"\"\n",
    "MATCH (a1:Artist), (a2:Artist)\n",
    "WHERE a1.name < a2.name\n",
    "WITH a1, a2\n",
    "MATCH (a1)-[:PERFORMED]->(t1:Track)<-[:PERFORMED]-(a2)\n",
    "WITH a1, a2, COUNT(t1) AS common_tracks\n",
    "WHERE common_tracks > 0\n",
    "MERGE (a1)-[r:SIMILAR_TO]-(a2)\n",
    "SET r.weight = common_tracks\n",
    "\"\"\")\n",
    "\n",
    "# Verify algorithms ran successfully\n",
    "count_result = session.run(\"\"\"\n",
    "MATCH (n) \n",
    "WHERE n.pagerank IS NOT NULL AND n.degree IS NOT NULL AND n.community IS NOT NULL\n",
    "RETURN count(n) AS count\n",
    "\"\"\").single()[\"count\"]\n",
    "\n",
    "similarity_count = session.run(\"MATCH ()-[r:SIMILAR_TO]-() RETURN COUNT(r) AS count\").single()[\"count\"]\n",
    "\n",
    "print(f\"Successfully ran algorithms on {count_result} nodes and created {similarity_count} similarity relationships\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8138132c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an artist-only projection for recommendations\n",
    "session.run(\"\"\"\n",
    "CALL gds.graph.project(\n",
    "    'artist_graph',\n",
    "    'Artist',\n",
    "    {\n",
    "        SIMILAR_TO: {\n",
    "            orientation: 'UNDIRECTED',\n",
    "            properties: {\n",
    "                weight: {\n",
    "                    property: 'weight',\n",
    "                    defaultValue: 1.0\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ");\n",
    "\"\"\")\n",
    "\n",
    "# Run PageRank on the artist graph\n",
    "session.run(\"\"\"\n",
    "CALL gds.pageRank.write('artist_graph', {\n",
    "    writeProperty: 'artist_pagerank',\n",
    "    relationshipWeightProperty: 'weight'\n",
    "})\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f810bff4",
   "metadata": {},
   "source": [
    "### Query Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce468e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Top nodes by PageRank\n",
    "pagerank_result = session.run(\"\"\"\n",
    "MATCH (n)\n",
    "WHERE n.pagerank IS NOT NULL\n",
    "RETURN labels(n)[0] AS type, n.name AS name, n.pagerank AS score\n",
    "ORDER BY score DESC\n",
    "LIMIT 10\n",
    "\"\"\")\n",
    "\n",
    "print(\"Top 10 Influential Nodes by PageRank:\")\n",
    "for record in pagerank_result:\n",
    "    print(f\"{record['type']}: {record['name']} (Score: {record['score']:.6f})\")\n",
    "\n",
    "# 2. Top nodes by Degree Centrality\n",
    "degree_result = session.run(\"\"\"\n",
    "MATCH (n)\n",
    "WHERE n.degree IS NOT NULL\n",
    "RETURN labels(n)[0] AS type, n.name AS name, n.degree AS score\n",
    "ORDER BY score DESC\n",
    "LIMIT 10\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nTop 10 Nodes by Degree Centrality:\")\n",
    "for record in degree_result:\n",
    "    print(f\"{record['type']}: {record['name']} (Score: {record['score']:.2f})\")\n",
    "\n",
    "# 3. Community detection results\n",
    "community_result = session.run(\"\"\"\n",
    "MATCH (n)\n",
    "WHERE n.community IS NOT NULL\n",
    "WITH n.community AS community, collect(n.name) AS members\n",
    "RETURN community, size(members) AS size, members[0..3] AS sample_members\n",
    "ORDER BY size DESC\n",
    "LIMIT 5\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nMusic Communities Detected:\")\n",
    "for record in community_result:\n",
    "    print(f\"Community {record['community']} (Size: {record['size']}): {record['sample_members']}\")\n",
    "\n",
    "# 4. Similar artist pairs\n",
    "similar_result = session.run(\"\"\"\n",
    "MATCH (a1:Artist)-[r:SIMILAR_TO]-(a2:Artist)\n",
    "RETURN a1.name AS artist1, a2.name AS artist2, r.weight AS commonTracks\n",
    "ORDER BY commonTracks DESC\n",
    "LIMIT 10\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nTop 10 Similar Artist Pairs:\")\n",
    "for record in similar_result:\n",
    "    print(f\"{record['artist1']} and {record['artist2']} share {record['commonTracks']} tracks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d7fd78",
   "metadata": {},
   "source": [
    "### Artist Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639cea37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get top artists by track count\n",
    "top_artists = session.run(\"\"\"\n",
    "MATCH (a:Artist)-[:PERFORMED]->(t)\n",
    "WITH a, COUNT(t) AS track_count\n",
    "RETURN a.name AS name\n",
    "ORDER BY track_count DESC\n",
    "LIMIT 3\n",
    "\"\"\")\n",
    "\n",
    "top_artist_names = [record[\"name\"] for record in top_artists]\n",
    "\n",
    "print(\"Recommendations for Top Artists:\")\n",
    "for artist in top_artist_names:\n",
    "    print(f\"\\nFor fans of {artist}:\")\n",
    "    \n",
    "    # Find similar artists based on tracks they've performed\n",
    "    similar = session.run(\"\"\"\n",
    "    MATCH (a:Artist {name: $artist})-[:PERFORMED]->(t:Track)<-[:PERFORMED]-(other:Artist)\n",
    "    WHERE a <> other\n",
    "    RETURN other.name AS name, COUNT(t) AS common_tracks\n",
    "    ORDER BY common_tracks DESC\n",
    "    LIMIT 3\n",
    "    \"\"\", artist=artist)\n",
    "    \n",
    "    similar_results = list(similar)\n",
    "    if similar_results:\n",
    "        print(\"Similar artists:\")\n",
    "        for record in similar_results:\n",
    "            print(f\"- {record['name']} (Common tracks: {record['common_tracks']})\")\n",
    "    else:\n",
    "        print(\"No similar artists found\")\n",
    "    \n",
    "    # Recommend tracks from artists in the same community\n",
    "    tracks = session.run(\"\"\"\n",
    "    MATCH (a:Artist {name: $artist})\n",
    "    MATCH (other:Artist)\n",
    "    WHERE other.community = a.community AND other <> a\n",
    "    MATCH (other)-[:PERFORMED]->(t:Track)\n",
    "    WHERE NOT EXISTS((a)-[:PERFORMED]->(t))\n",
    "    RETURN t.name AS track, other.name AS artist\n",
    "    LIMIT 3\n",
    "    \"\"\", artist=artist)\n",
    "    \n",
    "    track_results = list(tracks)\n",
    "    if track_results:\n",
    "        print(\"Recommended tracks:\")\n",
    "        for record in track_results:\n",
    "            print(f\"- {record['track']} by {record['artist']}\")\n",
    "    else:\n",
    "        print(\"No track recommendations found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a237bb",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8a2bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph summary statistics\n",
    "summary = session.run(\"\"\"\n",
    "MATCH (n)\n",
    "WHERE n.pagerank IS NOT NULL\n",
    "WITH \n",
    "    labels(n)[0] AS type,\n",
    "    count(n) AS count,\n",
    "    avg(n.pagerank) AS avg_pagerank,\n",
    "    max(n.pagerank) AS max_pagerank,\n",
    "    min(n.pagerank) AS min_pagerank,\n",
    "    avg(n.degree) AS avg_degree,\n",
    "    max(n.degree) AS max_degree,\n",
    "    min(n.degree) AS min_degree\n",
    "RETURN type, count, avg_pagerank, max_pagerank, min_pagerank, avg_degree, max_degree, min_degree\n",
    "ORDER BY type\n",
    "\"\"\")\n",
    "\n",
    "print(\"Graph Analysis Summary:\")\n",
    "for record in summary:\n",
    "    print(f\"Node type: {record['type']}\")\n",
    "    print(f\"  Count: {record['count']}\")\n",
    "    print(f\"  PageRank: Avg={record['avg_pagerank']:.6f}, Max={record['max_pagerank']:.6f}, Min={record['min_pagerank']:.6f}\")\n",
    "    print(f\"  Degree: Avg={record['avg_degree']:.2f}, Max={record['max_degree']:.2f}, Min={record['min_degree']:.2f}\")\n",
    "\n",
    "# Community counts\n",
    "community_stats = session.run(\"\"\"\n",
    "MATCH (n)\n",
    "WHERE n.community IS NOT NULL\n",
    "RETURN count(DISTINCT n.community) AS communityCount\n",
    "\"\"\")\n",
    "\n",
    "print(f\"\\nNumber of communities: {community_stats.single()['communityCount']}\")\n",
    "\n",
    "# Close Neo4j session\n",
    "#session.close()\n",
    "#driver.close()\n",
    "print(\"Neo4j graph analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e017b3",
   "metadata": {},
   "source": [
    "## Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9630f01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigation Cell - Neo4j Graph Diagnostics\n",
    "\n",
    "print(\"============ NEO4J GRAPH INVESTIGATION ============\")\n",
    "\n",
    "# 1. Check graph projections\n",
    "print(\"\\n1. CHECKING GRAPH PROJECTIONS:\")\n",
    "projection_info = session.run(\"\"\"\n",
    "CALL gds.graph.list()\n",
    "YIELD graphName, nodeCount, relationshipCount, schema\n",
    "RETURN graphName, nodeCount, relationshipCount, schema\n",
    "\"\"\")\n",
    "\n",
    "projections = list(projection_info)\n",
    "if projections:\n",
    "    for record in projections:\n",
    "        print(f\"Graph: {record['graphName']}\")\n",
    "        print(f\"  Nodes: {record['nodeCount']}\")\n",
    "        print(f\"  Relationships: {record['relationshipCount']}\")\n",
    "        print(f\"  Schema: {record['schema']}\")\n",
    "else:\n",
    "    print(\"No graph projections found.\")\n",
    "\n",
    "# 2. Check node and relationship counts\n",
    "print(\"\\n2. CHECKING NODE AND RELATIONSHIP COUNTS:\")\n",
    "node_counts = session.run(\"\"\"\n",
    "MATCH (n)\n",
    "RETURN labels(n)[0] AS type, count(n) AS count\n",
    "\"\"\")\n",
    "\n",
    "for record in node_counts:\n",
    "    print(f\"{record['type']}s: {record['count']}\")\n",
    "\n",
    "rel_counts = session.run(\"\"\"\n",
    "MATCH ()-[r]->()\n",
    "RETURN type(r) AS type, count(r) AS count\n",
    "\"\"\")\n",
    "\n",
    "for record in rel_counts:\n",
    "    print(f\"{record['type']} relationships: {record['count']}\")\n",
    "\n",
    "# 3. Check weight distribution on relationships\n",
    "print(\"\\n3. CHECKING RELATIONSHIP WEIGHT DISTRIBUTION:\")\n",
    "weight_stats = session.run(\"\"\"\n",
    "MATCH ()-[r:PERFORMED]->()\n",
    "RETURN \n",
    "    count(r) AS total,\n",
    "    avg(r.weight) AS avg_weight,\n",
    "    min(r.weight) AS min_weight,\n",
    "    max(r.weight) AS max_weight\n",
    "\"\"\")\n",
    "\n",
    "for record in weight_stats:\n",
    "    print(f\"PERFORMED relationships: {record['total']}\")\n",
    "    print(f\"  Average weight: {record['avg_weight']}\")\n",
    "    print(f\"  Min weight: {record['min_weight']}\")\n",
    "    print(f\"  Max weight: {record['max_weight']}\")\n",
    "\n",
    "# 4. Check connectivity between artists (how many share tracks)\n",
    "print(\"\\n4. CHECKING ARTIST CONNECTIVITY:\")\n",
    "artist_connectivity = session.run(\"\"\"\n",
    "MATCH (a1:Artist)-[:PERFORMED]->(t:Track)<-[:PERFORMED]-(a2:Artist)\n",
    "WHERE a1 <> a2\n",
    "RETURN count(DISTINCT [a1, a2]) AS artist_pairs\n",
    "\"\"\")\n",
    "\n",
    "for record in artist_connectivity:\n",
    "    print(f\"Artist pairs that share tracks: {record['artist_pairs']}\")\n",
    "\n",
    "# 5. Verify SIMILAR_TO relationships\n",
    "print(\"\\n5. CHECKING SIMILAR_TO RELATIONSHIPS:\")\n",
    "similar_stats = session.run(\"\"\"\n",
    "MATCH ()-[r:SIMILAR_TO]-()\n",
    "RETURN \n",
    "    count(r) AS total,\n",
    "    avg(r.weight) AS avg_weight,\n",
    "    min(r.weight) AS min_weight,\n",
    "    max(r.weight) AS max_weight\n",
    "\"\"\")\n",
    "\n",
    "for record in similar_stats:\n",
    "    print(f\"SIMILAR_TO relationships: {record['total']}\")\n",
    "    if record['total'] > 0:\n",
    "        print(f\"  Average weight: {record['avg_weight']}\")\n",
    "        print(f\"  Min weight: {record['min_weight']}\")\n",
    "        print(f\"  Max weight: {record['max_weight']}\")\n",
    "\n",
    "# 6. Test creating a new graph projection\n",
    "print(\"\\n6. TESTING NEW GRAPH PROJECTION:\")\n",
    "try:\n",
    "    session.run(\"CALL gds.graph.drop('test_graph', false)\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    new_projection = session.run(\"\"\"\n",
    "    CALL gds.graph.project(\n",
    "        'test_graph',\n",
    "        ['Artist', 'Track'],\n",
    "        {\n",
    "            PERFORMED: {\n",
    "                orientation: 'NATURAL',\n",
    "                properties: {\n",
    "                    weight: {\n",
    "                        property: 'weight',\n",
    "                        defaultValue: 1.0\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    YIELD graphName, nodeCount, relationshipCount\n",
    "    RETURN graphName, nodeCount, relationshipCount\n",
    "    \"\"\")\n",
    "    \n",
    "    record = new_projection.single()\n",
    "    print(f\"Created test projection: {record['graphName']}\")\n",
    "    print(f\"  Nodes: {record['nodeCount']}\")\n",
    "    print(f\"  Relationships: {record['relationshipCount']}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating test projection: {e}\")\n",
    "\n",
    "# 7. Test artist-only projection\n",
    "print(\"\\n7. TESTING ARTIST-ONLY PROJECTION:\")\n",
    "try:\n",
    "    session.run(\"CALL gds.graph.drop('artist_graph', false)\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# First create SIMILAR_TO relationships if they don't exist\n",
    "session.run(\"\"\"\n",
    "MATCH (a1:Artist)-[:PERFORMED]->(t:Track)<-[:PERFORMED]-(a2:Artist)\n",
    "WHERE a1 <> a2 AND id(a1) < id(a2)\n",
    "WITH a1, a2, COUNT(t) AS commonTracks\n",
    "WHERE commonTracks > 0\n",
    "MERGE (a1)-[r:SIMILAR_TO]-(a2)\n",
    "SET r.weight = commonTracks\n",
    "\"\"\")\n",
    "\n",
    "try:\n",
    "    artist_projection = session.run(\"\"\"\n",
    "    CALL gds.graph.project(\n",
    "        'artist_graph',\n",
    "        'Artist',\n",
    "        {\n",
    "            SIMILAR_TO: {\n",
    "                orientation: 'UNDIRECTED',\n",
    "                properties: {\n",
    "                    weight: {\n",
    "                        property: 'weight',\n",
    "                        defaultValue: 1.0\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    YIELD graphName, nodeCount, relationshipCount\n",
    "    RETURN graphName, nodeCount, relationshipCount\n",
    "    \"\"\")\n",
    "    \n",
    "    record = artist_projection.single()\n",
    "    print(f\"Created artist projection: {record['graphName']}\")\n",
    "    print(f\"  Nodes: {record['nodeCount']}\")\n",
    "    print(f\"  Relationships: {record['relationshipCount']}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating artist projection: {e}\")\n",
    "\n",
    "# 8. Test PageRank on Artist Graph\n",
    "print(\"\\n8. TESTING PAGERANK ON ARTIST GRAPH:\")\n",
    "try:\n",
    "    session.run(\"\"\"\n",
    "    CALL gds.pageRank.write('artist_graph', {\n",
    "        writeProperty: 'artist_pagerank',\n",
    "        relationshipWeightProperty: 'weight',\n",
    "        maxIterations: 20,\n",
    "        dampingFactor: 0.85\n",
    "    })\n",
    "    \"\"\")\n",
    "    \n",
    "    pagerank_result = session.run(\"\"\"\n",
    "    MATCH (a:Artist)\n",
    "    WHERE a.artist_pagerank IS NOT NULL\n",
    "    RETURN a.name AS name, a.artist_pagerank AS score\n",
    "    ORDER BY score DESC\n",
    "    LIMIT 5\n",
    "    \"\"\")\n",
    "    \n",
    "    print(\"Top 5 artists by PageRank:\")\n",
    "    for record in pagerank_result:\n",
    "        print(f\"  {record['name']}: {record['score']:.6f}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error running PageRank on artist graph: {e}\")\n",
    "\n",
    "# 9. Try alternative community detection\n",
    "print(\"\\n9. TESTING LABEL PROPAGATION:\")\n",
    "try:\n",
    "    session.run(\"\"\"\n",
    "    CALL gds.labelPropagation.write('artist_graph', {\n",
    "        writeProperty: 'artist_community'\n",
    "    })\n",
    "    \"\"\")\n",
    "    \n",
    "    community_result = session.run(\"\"\"\n",
    "    MATCH (a:Artist)\n",
    "    WHERE a.artist_community IS NOT NULL\n",
    "    RETURN a.artist_community AS community, count(*) AS size\n",
    "    ORDER BY size DESC\n",
    "    LIMIT 5\n",
    "    \"\"\")\n",
    "    \n",
    "    print(\"Top 5 artist communities:\")\n",
    "    for record in community_result:\n",
    "        print(f\"  Community {record['community']}: {record['size']} artists\")\n",
    "        \n",
    "    # Get sample members\n",
    "    for record in community_result:\n",
    "        community_id = record['community']\n",
    "        sample = session.run(\"\"\"\n",
    "        MATCH (a:Artist)\n",
    "        WHERE a.artist_community = $community\n",
    "        RETURN a.name AS name\n",
    "        LIMIT 3\n",
    "        \"\"\", community=community_id)\n",
    "        \n",
    "        names = [r['name'] for r in sample]\n",
    "        print(f\"  Sample from community {community_id}: {names}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error running Label Propagation on artist graph: {e}\")\n",
    "\n",
    "# 10. Check which algorithms are available\n",
    "print(\"\\n10. CHECKING AVAILABLE ALGORITHMS:\")\n",
    "try:\n",
    "    algo_list = session.run(\"\"\"\n",
    "    CALL gds.list()\n",
    "    YIELD name, description\n",
    "    RETURN name, description\n",
    "    LIMIT 10\n",
    "    \"\"\")\n",
    "    \n",
    "    print(\"Sample of available algorithms:\")\n",
    "    for record in algo_list:\n",
    "        print(f\"  {record['name']}: {record['description']}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error listing algorithms: {e}\")\n",
    "\n",
    "print(\"\\n============ INVESTIGATION COMPLETE ============\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be23485e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
